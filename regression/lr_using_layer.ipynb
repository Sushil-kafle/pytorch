{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device('cuda')\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= make_regression(1000,n_features=4,noise=0.4,random_state=seed)\n",
    "y=y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= torch.tensor(X,dtype=torch.float)\n",
    "y= torch.tensor(y,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_layer=nn.Linear(in_features=4,\n",
    "                                    out_features=1\n",
    "                                    )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.linear_layer(x)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight',\n",
       "              tensor([[-0.2592, -0.3868, -0.3155, -0.3437]], device='cuda:0')),\n",
       "             ('linear_layer.bias', tensor([0.2877], device='cuda:0'))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:0 loss=99.22102355957031 val_loss=109.93970489501953\n",
      "epochs:10 loss=98.55667877197266 val_loss=109.20673370361328\n",
      "epochs:20 loss=97.89230346679688 val_loss=108.4737777709961\n",
      "epochs:30 loss=97.22795867919922 val_loss=107.74081420898438\n",
      "epochs:40 loss=96.56359100341797 val_loss=107.00785827636719\n",
      "epochs:50 loss=95.89924621582031 val_loss=106.27490234375\n",
      "epochs:60 loss=95.23489379882812 val_loss=105.54193878173828\n",
      "epochs:70 loss=94.57052612304688 val_loss=104.8089828491211\n",
      "epochs:80 loss=93.90616607666016 val_loss=104.07601165771484\n",
      "epochs:90 loss=93.2418212890625 val_loss=103.34305572509766\n",
      "epochs:100 loss=92.57746124267578 val_loss=102.61009216308594\n",
      "epochs:110 loss=91.91384887695312 val_loss=101.87734985351562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:120 loss=91.25161743164062 val_loss=101.14480590820312\n",
      "epochs:130 loss=90.58939361572266 val_loss=100.41226196289062\n",
      "epochs:140 loss=89.92716217041016 val_loss=99.67971801757812\n",
      "epochs:150 loss=89.26513671875 val_loss=98.94681549072266\n",
      "epochs:160 loss=88.6031265258789 val_loss=98.21387481689453\n",
      "epochs:170 loss=87.94112396240234 val_loss=97.48094177246094\n",
      "epochs:180 loss=87.279296875 val_loss=96.74769592285156\n",
      "epochs:190 loss=86.61759948730469 val_loss=96.01432037353516\n",
      "epochs:200 loss=85.9559326171875 val_loss=95.28060150146484\n",
      "epochs:210 loss=85.2942886352539 val_loss=94.54683685302734\n",
      "epochs:220 loss=84.63263702392578 val_loss=93.81306457519531\n",
      "epochs:230 loss=83.97099304199219 val_loss=93.07930755615234\n",
      "epochs:240 loss=83.30933380126953 val_loss=92.34554290771484\n",
      "epochs:250 loss=82.64768981933594 val_loss=91.61177825927734\n",
      "epochs:260 loss=81.98605346679688 val_loss=90.87800598144531\n",
      "epochs:270 loss=81.32439422607422 val_loss=90.14424896240234\n",
      "epochs:280 loss=80.66301727294922 val_loss=89.41020202636719\n",
      "epochs:290 loss=80.00215911865234 val_loss=88.67630004882812\n",
      "epochs:300 loss=79.34138488769531 val_loss=87.94242095947266\n",
      "epochs:310 loss=78.68060302734375 val_loss=87.20854949951172\n",
      "epochs:320 loss=78.01982879638672 val_loss=86.47468566894531\n",
      "epochs:330 loss=77.3593521118164 val_loss=85.7410659790039\n",
      "epochs:340 loss=76.69898986816406 val_loss=85.00749969482422\n",
      "epochs:350 loss=76.03861999511719 val_loss=84.27394104003906\n",
      "epochs:360 loss=75.37825012207031 val_loss=83.54039001464844\n",
      "epochs:370 loss=74.71788787841797 val_loss=82.80682373046875\n",
      "epochs:380 loss=74.0579605102539 val_loss=82.07351684570312\n",
      "epochs:390 loss=73.39838409423828 val_loss=81.34062194824219\n",
      "epochs:400 loss=72.73884582519531 val_loss=80.60780334472656\n",
      "epochs:410 loss=72.07931518554688 val_loss=79.87498474121094\n",
      "epochs:420 loss=71.41989135742188 val_loss=79.1423110961914\n",
      "epochs:430 loss=70.76070404052734 val_loss=78.40982055664062\n",
      "epochs:440 loss=70.10150909423828 val_loss=77.67733001708984\n",
      "epochs:450 loss=69.44232177734375 val_loss=76.94485473632812\n",
      "epochs:460 loss=68.78312683105469 val_loss=76.21236419677734\n",
      "epochs:470 loss=68.12393951416016 val_loss=75.47987365722656\n",
      "epochs:480 loss=67.4647445678711 val_loss=74.74739074707031\n",
      "epochs:490 loss=66.80555725097656 val_loss=74.01490020751953\n",
      "epochs:500 loss=66.14671325683594 val_loss=73.28265380859375\n",
      "epochs:510 loss=65.48818969726562 val_loss=72.5507583618164\n",
      "epochs:520 loss=64.82965087890625 val_loss=71.81974792480469\n",
      "epochs:530 loss=64.1711196899414 val_loss=71.0887222290039\n",
      "epochs:540 loss=63.51302719116211 val_loss=70.35783386230469\n",
      "epochs:550 loss=62.85531234741211 val_loss=69.62702941894531\n",
      "epochs:560 loss=62.19758605957031 val_loss=68.89623260498047\n",
      "epochs:570 loss=61.53987121582031 val_loss=68.16543579101562\n",
      "epochs:580 loss=60.88214874267578 val_loss=67.43462371826172\n",
      "epochs:590 loss=60.22443389892578 val_loss=66.70382690429688\n",
      "epochs:600 loss=59.566707611083984 val_loss=65.9730224609375\n",
      "epochs:610 loss=58.90898895263672 val_loss=65.24222564697266\n",
      "epochs:620 loss=58.25142288208008 val_loss=64.51179504394531\n",
      "epochs:630 loss=57.594051361083984 val_loss=63.78173828125\n",
      "epochs:640 loss=56.93688201904297 val_loss=63.05186462402344\n",
      "epochs:650 loss=56.28085708618164 val_loss=62.32282257080078\n",
      "epochs:660 loss=55.62486267089844 val_loss=61.59377670288086\n",
      "epochs:670 loss=54.96885681152344 val_loss=60.86472702026367\n",
      "epochs:680 loss=54.3128547668457 val_loss=60.13568115234375\n",
      "epochs:690 loss=53.65685272216797 val_loss=59.406639099121094\n",
      "epochs:700 loss=53.0008544921875 val_loss=58.67759323120117\n",
      "epochs:710 loss=52.344852447509766 val_loss=57.94858169555664\n",
      "epochs:720 loss=51.688880920410156 val_loss=57.21992111206055\n",
      "epochs:730 loss=51.03289794921875 val_loss=56.49126434326172\n",
      "epochs:740 loss=50.37693405151367 val_loss=55.76260757446289\n",
      "epochs:750 loss=49.72097396850586 val_loss=55.03398132324219\n",
      "epochs:760 loss=49.06554412841797 val_loss=54.30585479736328\n",
      "epochs:770 loss=48.410667419433594 val_loss=53.57833480834961\n",
      "epochs:780 loss=47.75582504272461 val_loss=52.85081481933594\n",
      "epochs:790 loss=47.10099411010742 val_loss=52.12310791015625\n",
      "epochs:800 loss=46.446170806884766 val_loss=51.39568328857422\n",
      "epochs:810 loss=45.79135513305664 val_loss=50.668216705322266\n",
      "epochs:820 loss=45.13653564453125 val_loss=49.94075012207031\n",
      "epochs:830 loss=44.48171615600586 val_loss=49.213279724121094\n",
      "epochs:840 loss=43.8268928527832 val_loss=48.48581314086914\n",
      "epochs:850 loss=43.172080993652344 val_loss=47.75835037231445\n",
      "epochs:860 loss=42.51725387573242 val_loss=47.03168869018555\n",
      "epochs:870 loss=41.86243438720703 val_loss=46.30507278442383\n",
      "epochs:880 loss=41.20761489868164 val_loss=45.5784912109375\n",
      "epochs:890 loss=40.55279541015625 val_loss=44.85187530517578\n",
      "epochs:900 loss=39.897979736328125 val_loss=44.12525177001953\n",
      "epochs:910 loss=39.24315643310547 val_loss=43.398643493652344\n",
      "epochs:920 loss=38.58835220336914 val_loss=42.67206573486328\n",
      "epochs:930 loss=37.93375778198242 val_loss=41.945735931396484\n",
      "epochs:940 loss=37.279170989990234 val_loss=41.21941375732422\n",
      "epochs:950 loss=36.624576568603516 val_loss=40.49308395385742\n",
      "epochs:960 loss=35.96998596191406 val_loss=39.76675796508789\n",
      "epochs:970 loss=35.31539535522461 val_loss=39.04043197631836\n",
      "epochs:980 loss=34.66080093383789 val_loss=38.31410598754883\n",
      "epochs:990 loss=34.0062141418457 val_loss=37.58777618408203\n",
      "epochs:1000 loss=33.35194778442383 val_loss=36.86177062988281\n",
      "epochs:1010 loss=32.69770812988281 val_loss=36.13576889038086\n",
      "epochs:1020 loss=32.043739318847656 val_loss=35.410606384277344\n",
      "epochs:1030 loss=31.389955520629883 val_loss=34.686317443847656\n",
      "epochs:1040 loss=30.736379623413086 val_loss=33.96218490600586\n",
      "epochs:1050 loss=30.08284568786621 val_loss=33.23831558227539\n",
      "epochs:1060 loss=29.429325103759766 val_loss=32.51450729370117\n",
      "epochs:1070 loss=28.77580451965332 val_loss=31.79069709777832\n",
      "epochs:1080 loss=28.12228775024414 val_loss=31.0668888092041\n",
      "epochs:1090 loss=27.468769073486328 val_loss=30.34308433532715\n",
      "epochs:1100 loss=26.815248489379883 val_loss=29.61927604675293\n",
      "epochs:1110 loss=26.161996841430664 val_loss=28.89556121826172\n",
      "epochs:1120 loss=25.509273529052734 val_loss=28.171981811523438\n",
      "epochs:1130 loss=24.856884002685547 val_loss=27.448627471923828\n",
      "epochs:1140 loss=24.204723358154297 val_loss=26.725465774536133\n",
      "epochs:1150 loss=23.55291748046875 val_loss=26.0026798248291\n",
      "epochs:1160 loss=22.901113510131836 val_loss=25.279891967773438\n",
      "epochs:1170 loss=22.2495059967041 val_loss=24.557424545288086\n",
      "epochs:1180 loss=21.597911834716797 val_loss=23.83495330810547\n",
      "epochs:1190 loss=20.94632339477539 val_loss=23.11249542236328\n",
      "epochs:1200 loss=20.294816970825195 val_loss=22.390209197998047\n",
      "epochs:1210 loss=19.643402099609375 val_loss=21.6680850982666\n",
      "epochs:1220 loss=18.992122650146484 val_loss=20.94611358642578\n",
      "epochs:1230 loss=18.341169357299805 val_loss=20.224437713623047\n",
      "epochs:1240 loss=17.690509796142578 val_loss=19.503053665161133\n",
      "epochs:1250 loss=17.03984832763672 val_loss=18.78166961669922\n",
      "epochs:1260 loss=16.38921546936035 val_loss=18.060503005981445\n",
      "epochs:1270 loss=15.738603591918945 val_loss=17.339427947998047\n",
      "epochs:1280 loss=15.089200973510742 val_loss=16.61953353881836\n",
      "epochs:1290 loss=14.4402437210083 val_loss=15.900007247924805\n",
      "epochs:1300 loss=13.791736602783203 val_loss=15.180700302124023\n",
      "epochs:1310 loss=13.143888473510742 val_loss=14.46212100982666\n",
      "epochs:1320 loss=12.496443748474121 val_loss=13.744423866271973\n",
      "epochs:1330 loss=11.84919261932373 val_loss=13.026838302612305\n",
      "epochs:1340 loss=11.20245361328125 val_loss=12.309802055358887\n",
      "epochs:1350 loss=10.556211471557617 val_loss=11.593461990356445\n",
      "epochs:1360 loss=9.910255432128906 val_loss=10.87759017944336\n",
      "epochs:1370 loss=9.264975547790527 val_loss=10.162150382995605\n",
      "epochs:1380 loss=8.620911598205566 val_loss=9.446372032165527\n",
      "epochs:1390 loss=7.977500915527344 val_loss=8.731232643127441\n",
      "epochs:1400 loss=7.334412097930908 val_loss=8.016532897949219\n",
      "epochs:1410 loss=6.691369533538818 val_loss=7.302235126495361\n",
      "epochs:1420 loss=6.048325538635254 val_loss=6.588022232055664\n",
      "epochs:1430 loss=5.405457496643066 val_loss=5.875568866729736\n",
      "epochs:1440 loss=4.764808654785156 val_loss=5.166513442993164\n",
      "epochs:1450 loss=4.126551628112793 val_loss=4.46013069152832\n",
      "epochs:1460 loss=3.489776611328125 val_loss=3.75557541847229\n",
      "epochs:1470 loss=2.854816436767578 val_loss=3.0533440113067627\n",
      "epochs:1480 loss=2.225349187850952 val_loss=2.358475685119629\n",
      "epochs:1490 loss=1.605903148651123 val_loss=1.6754469871520996\n",
      "epochs:1500 loss=1.0073208808898926 val_loss=1.0224380493164062\n",
      "epochs:1510 loss=0.4963153600692749 val_loss=0.48826709389686584\n",
      "epochs:1520 loss=0.3257041871547699 val_loss=0.32086142897605896\n",
      "epochs:1530 loss=0.3182968199253082 val_loss=0.31319189071655273\n",
      "epochs:1540 loss=0.31796520948410034 val_loss=0.3137838542461395\n",
      "epochs:1550 loss=0.31791195273399353 val_loss=0.31430938839912415\n",
      "epochs:1560 loss=0.31791290640830994 val_loss=0.31427329778671265\n",
      "epochs:1570 loss=0.31791120767593384 val_loss=0.3143409788608551\n",
      "epochs:1580 loss=0.31791234016418457 val_loss=0.314326673746109\n",
      "epochs:1590 loss=0.3179118037223816 val_loss=0.31434839963912964\n",
      "epochs:1600 loss=0.3179125189781189 val_loss=0.31433871388435364\n",
      "epochs:1610 loss=0.3179108202457428 val_loss=0.3142869472503662\n",
      "epochs:1620 loss=0.31791168451309204 val_loss=0.31430584192276\n",
      "epochs:1630 loss=0.3179120123386383 val_loss=0.31430524587631226\n",
      "epochs:1640 loss=0.3179113566875458 val_loss=0.3143317997455597\n",
      "epochs:1650 loss=0.31791308522224426 val_loss=0.3143928349018097\n",
      "epochs:1660 loss=0.3179132342338562 val_loss=0.31440380215644836\n",
      "epochs:1670 loss=0.317912220954895 val_loss=0.31438565254211426\n",
      "epochs:1680 loss=0.317912757396698 val_loss=0.314338356256485\n",
      "epochs:1690 loss=0.31791505217552185 val_loss=0.3144208788871765\n",
      "epochs:1700 loss=0.31791090965270996 val_loss=0.3143238425254822\n",
      "epochs:1710 loss=0.3179110884666443 val_loss=0.3143465220928192\n",
      "epochs:1720 loss=0.3179105222225189 val_loss=0.3142974078655243\n",
      "epochs:1730 loss=0.31791090965270996 val_loss=0.3143293261528015\n",
      "epochs:1740 loss=0.3179105818271637 val_loss=0.3143065571784973\n",
      "epochs:1750 loss=0.3179115355014801 val_loss=0.3143208920955658\n",
      "epochs:1760 loss=0.3179125189781189 val_loss=0.3143218755722046\n",
      "epochs:1770 loss=0.31791210174560547 val_loss=0.3143743872642517\n",
      "epochs:1780 loss=0.31791234016418457 val_loss=0.3143354654312134\n",
      "epochs:1790 loss=0.3179132640361786 val_loss=0.3142712414264679\n",
      "epochs:1800 loss=0.31791171431541443 val_loss=0.3143335282802582\n",
      "epochs:1810 loss=0.317912220954895 val_loss=0.3143927752971649\n",
      "epochs:1820 loss=0.31791120767593384 val_loss=0.3143891990184784\n",
      "epochs:1830 loss=0.3179117441177368 val_loss=0.3142969608306885\n",
      "epochs:1840 loss=0.31791141629219055 val_loss=0.31442970037460327\n",
      "epochs:1850 loss=0.31791234016418457 val_loss=0.314380019903183\n",
      "epochs:1860 loss=0.317912220954895 val_loss=0.31427571177482605\n",
      "epochs:1870 loss=0.317912220954895 val_loss=0.3143424987792969\n",
      "epochs:1880 loss=0.3179129362106323 val_loss=0.31436586380004883\n",
      "epochs:1890 loss=0.31791383028030396 val_loss=0.314349889755249\n",
      "epochs:1900 loss=0.31791266798973083 val_loss=0.3143428862094879\n",
      "epochs:1910 loss=0.3179107904434204 val_loss=0.3142753541469574\n",
      "epochs:1920 loss=0.3179111182689667 val_loss=0.31431275606155396\n",
      "epochs:1930 loss=0.3179126977920532 val_loss=0.3142798840999603\n",
      "epochs:1940 loss=0.3179130554199219 val_loss=0.3142896294593811\n",
      "epochs:1950 loss=0.31791046261787415 val_loss=0.3143675625324249\n",
      "epochs:1960 loss=0.3179102838039398 val_loss=0.3142887353897095\n",
      "epochs:1970 loss=0.31791406869888306 val_loss=0.3143533766269684\n",
      "epochs:1980 loss=0.3179115653038025 val_loss=0.31437668204307556\n",
      "epochs:1990 loss=0.3179108500480652 val_loss=0.3143094778060913\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "loss_list=[]\n",
    "val_loss_list=[]\n",
    "for i in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "\n",
    "    loss = loss_fn(y_pred,y_train)\n",
    "\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        y_pred = model(X_test)\n",
    "        val_loss = loss_fn(y_pred,y_test)\n",
    "        val_loss_list.append(val_loss.item())\n",
    "    \n",
    "    if i%10 ==0:\n",
    "        print(f\"epochs:{i} loss={loss} val_loss={val_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
